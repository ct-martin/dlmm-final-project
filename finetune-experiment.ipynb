{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning an Image Caption model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU is detected by CUDA\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CPU is supported by IPEX\n",
    "#import intel_extension_for_pytorch as ipex\n",
    "#\n",
    "#print(ipex.cpu.runtime.is_runtime_ext_enabled())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration, default_data_collator, get_linear_schedule_with_warmup\n",
    "from peft import LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model, prepare_model_for_int8_training\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "checkpoint = \"Salesforce/blip-image-captioning-base\"\n",
    "model_name = checkpoint.split(\"/\")[1]\n",
    "\n",
    "config = LoraConfig(r=32, lora_alpha=64, target_modules=[\"qkv\"], lora_dropout=0.05, bias=\"none\")\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(checkpoint)\n",
    "model = BlipForConditionalGeneration.from_pretrained(checkpoint, load_in_8bit=True)#.to(device)\n",
    "#print(model)\n",
    "\n",
    "print(model.get_memory_footprint())\n",
    "\n",
    "#model.save_pretrained(f\"{model_name}-8bit-pre-peft\")\n",
    "#processor.save_pretrained(f\"{model_name}-8bit-pre-peft\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEFT Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_int8_training(model)\n",
    "model = get_peft_model(model, config)\n",
    "print(model.print_trainable_parameters())\n",
    "\n",
    "print(model.get_memory_footprint())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained(f\"{model_name}-quantized\")\n",
    "#processor.save_pretrained(f\"{model_name}-quantized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('ids_train.csv')\n",
    "#df_test = pd.read_csv('ids_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Remove Stopwords & Commas\n",
    "# \"Why?\" - this shouldn't be necessary but the model is pretty much only\n",
    "# outputting stopwords or commas; we're removing them to try to force it\n",
    "# to not do this. This may break semantic understanding slightly but\n",
    "# hopefully will give a better result.\n",
    "def remove_junk(text):\n",
    "  tokens = word_tokenize(text.replace(\",\",\"\"))\n",
    "  tokens = [tok for tok in tokens if tok.lower() not in stop_words]\n",
    "  return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Image\n",
    "\n",
    "def prep_data(df):\n",
    "  files = [f\"media/{media_id}.jpg\" for media_id in df['media_id'].to_list()]\n",
    "  descriptions = [remove_junk(text) for text in df['description'].to_list()]\n",
    "\n",
    "  return Dataset.from_dict({ \"image\": files, \"text\": descriptions }).cast_column(\"image\", Image())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = prep_data(df_train.head(1000))\n",
    "#ds_test = prep_data(df_test)\n",
    "\n",
    "ds_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train\n",
    "#del df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from textwrap import wrap\n",
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "#\n",
    "#def plot_images(images, captions):\n",
    "#    plt.figure(figsize=(20, 20))\n",
    "#    for i in range(len(images)):\n",
    "#        ax = plt.subplot(1, len(images), i + 1)\n",
    "#        caption = captions[i]\n",
    "#        caption = \"\\n\".join(wrap(caption, 12))\n",
    "#        plt.title(caption)\n",
    "#        plt.imshow(images[i])\n",
    "#        plt.axis(\"off\")\n",
    "#\n",
    "#sample_images_to_visualize = [np.array(ds_train[i][\"image\"]) for i in range(5)]\n",
    "#sample_captions = [ds_train[i][\"text\"] for i in range(5)]\n",
    "#plot_images(sample_images_to_visualize, sample_captions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/tasks/image_captioning\n",
    "def transforms(example_batch):\n",
    "    images = [x.convert(\"RGB\").resize((100,100)) for x in example_batch[\"image\"]]\n",
    "    captions = [x for x in example_batch[\"text\"]]\n",
    "    inputs = processor(images=images, text=captions, padding=\"max_length\")\n",
    "    inputs.update({\"labels\": inputs[\"input_ids\"]})\n",
    "    return inputs\n",
    "\n",
    "\n",
    "ds_train.set_transform(transforms)\n",
    "#ds_test.set_transform(transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import torch\n",
    "\n",
    "rouge = evaluate.load('rouge')\n",
    "#wer = evaluate.load('wer')\n",
    "#bleu = evaluate.load('bleu')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predicted = logits.argmax(-1)\n",
    "    decoded_labels = processor.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_predictions = processor.batch_decode(predicted, skip_special_tokens=True)\n",
    "    score = rouge.compute(predictions=decoded_predictions, references=decoded_labels)\n",
    "    #score = wer.compute(predictions=decoded_predictions, references=decoded_labels)\n",
    "    #score = bleu.compute(predictions=decoded_predictions, references=decoded_labels)\n",
    "    return {\"score\": score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Model saving\n",
    "    output_dir=f\"{model_name}-wip-2\",\n",
    "    push_to_hub=False,\n",
    "    # Hardware support\n",
    "    #fp16=True,\n",
    "    #use_cpu=True,\n",
    "    #use_ipex=True,\n",
    "    # Basics\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=5e-5,\n",
    "    label_names=[\"labels\"],\n",
    "    # Other\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    save_total_limit=3,\n",
    "    evaluation_strategy=\"no\",\n",
    "    #evaluation_strategy=\"steps\",\n",
    "    #eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=250,\n",
    "    logging_steps=250,\n",
    "    remove_unused_columns=False,\n",
    "    #load_best_model_at_end=True,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_train,\n",
    "    #eval_dataset=ds_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "#torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(f\"{model_name}-quicktest\")\n",
    "processor.save_pretrained(f\"{model_name}-quicktest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
